{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.8.3-cp39-cp39-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.0-cp39-cp39-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.49.0-cp39-cp39-win_amd64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\project\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\project\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (23.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-10.2.0-cp39-cp39-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\project\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Using cached importlib_resources-6.1.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\project\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\project\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached matplotlib-3.8.3-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "Using cached contourpy-1.2.0-cp39-cp39-win_amd64.whl (181 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.49.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Using cached importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl (56 kB)\n",
      "Using cached pillow-10.2.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 importlib-resources-6.1.2 kiwisolver-1.4.5 matplotlib-3.8.3 pillow-10.2.0 pyparsing-3.1.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from densenetmodel import create_model\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_metrics(history):\n",
    "    # Plot accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def plot_interpretability(images, predictions, class_names):\n",
    "    # Select 5 random images\n",
    "    random_indices = random.sample(range(len(images)), 5)\n",
    "    selected_images = images[random_indices]\n",
    "    selected_predictions = predictions[random_indices]\n",
    "\n",
    "    # Plot the images and their predicted classes\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for i, (image, prediction) in enumerate(zip(selected_images, selected_predictions)):\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Predicted Class: {class_names[prediction]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths, image_size=(280, 280)):\n",
    "    \"\"\"\n",
    "    This function loads grayscale images from disk based on their file paths and resizes them to a consistent size.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "\n",
    "    for img_file in image_paths:\n",
    "        # create the full input path and read the file\n",
    "        image_path = os.path.join('Dataset/images/', img_file)\n",
    "        \n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # duplicate the grayscale image across three channels\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        images.append(image)\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def test_model(x_train, y_train, x_test, y_test):\n",
    "    # dimensions of our images.\n",
    "    img_width, img_height = 280, 280\n",
    "\n",
    "    # specify the number of classes\n",
    "    num_classes = 2\n",
    "\n",
    "    # create the base pre-trained model\n",
    "    # create the base pre-trained model\n",
    "    model = create_model((img_width, img_height, 3), num_classes)\n",
    "\n",
    "\n",
    "    # define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=32, callbacks=[early_stopping, learning_rate_reduction])\n",
    "\n",
    "    # save weights to file\n",
    "    model.save_weights('model_weights.h5')\n",
    "\n",
    "    # predict the output \n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # get the class with highest probability for each sample\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # load data\n",
    "    x_train_paths = np.load('Dataset/X_train.npy', allow_pickle=True)\n",
    "    y_train = np.load('Dataset/y_train.npy', allow_pickle=True)\n",
    "    x_test_paths = np.load('Dataset/X_test.npy', allow_pickle=True)\n",
    "    y_test = np.load('Dataset/y_test.npy', allow_pickle=True)\n",
    "\n",
    "    x_train = load_images(x_train_paths)\n",
    "    x_test = load_images(x_test_paths)\n",
    "\n",
    "    # test model\n",
    "    y_pred = test_model(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    accuracy = BinaryAccuracy()\n",
    "    accuracy.update_state(y_test, y_pred)\n",
    "    print('Test accuracy:', accuracy.result().numpy())\n",
    "\n",
    "    class_names = [0, 1]  # Replace with your class names\n",
    "    plot_interpretability(x_test, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m x_test_paths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset/X_test.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset/y_test.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m x_test \u001b[38;5;241m=\u001b[39m load_images(x_test_paths)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# test model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m, in \u001b[0;36mload_images\u001b[1;34m(image_paths, image_size)\u001b[0m\n\u001b[0;32m     11\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# duplicate the grayscale image across three channels\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_GRAY2BGR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
